{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb8bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "open_ai_key = \"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\"\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1-nano-2025-04-14\", model_provider=\"openai\", openai_api_key=open_ai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b155e26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tools.info_extractor' from '/Users/prajwalchaudhary/Desktop/Uni/COMP8420/AutoAgentML/tools/info_extractor.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import agents.eda_agent\n",
    "import agents.model_training_agent\n",
    "import tools.info_extractor\n",
    "importlib.reload(agents.model_training_agent)\n",
    "importlib.reload(agents.eda_agent)\n",
    "importlib.reload(tools.info_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccac8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Optional\n",
    "\n",
    "from langgraph.graph import StateGraph, START\n",
    "# from langgraph.checkpoint import MemorySaver\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, messages_from_dict, message_to_dict\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "from tools.info_extractor import info_extractor as ie\n",
    "\n",
    "from agents.eda_agent import EDAAgent\n",
    "from agents.model_training_agent import ModelTrainingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4a3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "orch_prompt = \"\"\"\n",
    "You are an intelligent machine learning assistant that guides users through setting up ML tasks. Your job is to have a professional, efficient conversation to collect the **minimum required information** so that specialized agents (like EdaAgent, FeatureEngineeringAgent, and ModelTrainingAgent) can take over.\n",
    "\n",
    "ðŸŽ¯ Your responsibilities:\n",
    "- Determine the **intent** of the user: Do they want to run EDA, do feature engineering, train a model, or run a full pipeline?\n",
    "- Collect only essential input:\n",
    "  - Dataset directory path (e.g., `./data/train.csv`)\n",
    "  - Type of data (e.g., `csv`, `images`, `text`, etc.)\n",
    "  - Type of task (e.g., `regression`, `classification`, `clustering`, `reinforcement learning`)\n",
    "  - Target column, if the task is supervised\n",
    "\n",
    "ðŸ§  What *not* to do:\n",
    "- Do **not** suggest or select specific models or metrics â€” that is the job of downstream agents.\n",
    "- Do **not** ask the user for algorithms, architectures, or training details.\n",
    "- Do **not** continue once enough information is collected.\n",
    "\n",
    "âœ… When you have everything:\n",
    "- Confirm with the user\n",
    "- Return the following fields:\n",
    "  - `data_path`\n",
    "  - `data_type`\n",
    "  - `task_type`\n",
    "  - `target_column` (if applicable)\n",
    "  - `task_intent` (e.g., `eda`, `model_training`, `full_pipeline`)\n",
    "  - `agents_to_call` = list of selected agents based on intent\n",
    "\n",
    "Examples:\n",
    "- If user says: \"I want to run EDA on ./data.csv\" â†’ set task_intent: `eda`, agents_to_call: `[\"EdaAgent\"]`\n",
    "- If user says: \"I want to build a model to predict price from a CSV file\" â†’ set task_type: `regression`, task_intent: `full_pipeline`, collect target column\n",
    "\n",
    "Respond in a professional and concise tone.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    orch_prompt,\n",
    "                ),\n",
    "                MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2fbad4",
   "metadata": {},
   "source": [
    "## CUstom Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "869146c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FILE MEMORY ===\n",
    "class MLTaskFileMemory:\n",
    "    def __init__(self, base_dir=\"ml_task_memory\"):\n",
    "        self.base_dir = base_dir\n",
    "        os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    def _msg_path(self, thread_id):\n",
    "        return os.path.join(self.base_dir, f\"messages_{thread_id}.json\")\n",
    "\n",
    "    def _info_path(self, thread_id):\n",
    "        return os.path.join(self.base_dir, f\"info_{thread_id}.json\")\n",
    "\n",
    "    def save_messages(self, thread_id, messages: List[BaseMessage]):\n",
    "        with open(self._msg_path(thread_id), \"w\") as f:\n",
    "            json.dump([message_to_dict(m) for m in messages], f, indent=2)\n",
    "\n",
    "    def load_messages(self, thread_id):\n",
    "        try:\n",
    "            with open(self._msg_path(thread_id), \"r\") as f:\n",
    "                content = f.read().strip()\n",
    "                return messages_from_dict(json.loads(content)) if content else []\n",
    "        except (FileNotFoundError, json.JSONDecodeError):\n",
    "            return []\n",
    "\n",
    "    def save_info(self, thread_id, task_type, target_column, agents_to_call, data_path=None, data_type=None, task_intent=None):\n",
    "        info = {\n",
    "            \"session_id\": thread_id,\n",
    "            \"data_path\": data_path,\n",
    "            \"data_type\": data_type,\n",
    "            \"task_type\": task_type,\n",
    "            \"target_column\": target_column,\n",
    "            \"task_intent\": task_intent,\n",
    "            \"agents_to_call\": agents_to_call,\n",
    "            \"model_type\": \"auto\",\n",
    "            \"metrics\": \"auto\",\n",
    "            \"status\": \"ready\",\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        with open(self._info_path(thread_id), \"w\") as f:\n",
    "            json.dump(info, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86edd7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === ORCHESTRATOR ===\n",
    "class Orchestrator:\n",
    "    def __init__(self):\n",
    "        workflow = StateGraph(state_schema=dict)\n",
    "        workflow.add_edge(START, \"model\")\n",
    "        workflow.add_node(\"model\", self.call_model)\n",
    "\n",
    "        memory = MemorySaver()\n",
    "        self.app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "        self.file_memory = MLTaskFileMemory()\n",
    "\n",
    "    def prompt_template_getter(self):\n",
    "        return ChatPromptTemplate.from_messages([\n",
    "            (\"system\", orch_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"messages\")\n",
    "        ])\n",
    "\n",
    "    def call_model(self, state: dict):\n",
    "        prompt = self.prompt_template_getter().invoke({\"messages\": state[\"messages\"]})\n",
    "        response = model.invoke(prompt)\n",
    "        return {\"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "    def is_info_complete(self, info: dict):\n",
    "        required_fields = [\"dataset_path\", \"task_intent\", \"agents_to_call\"]\n",
    "        return all(info.get(field) for field in required_fields)\n",
    "\n",
    "    def call_agents(self, info: dict, thread_id):\n",
    "        for agent in info[\"agents_to_call\"]:\n",
    "            print(agent)\n",
    "            if agent == \"EDAAgent\":\n",
    "                print(\"ðŸ“Š Calling EDA Agent...\")\n",
    "                # eda_agent.run(info[\"data_path\"]) or enqueue job\n",
    "                eda_agent = EDAAgent(thread_id)\n",
    "                eda_agent.run()\n",
    "\n",
    "            elif agent == \"FeatureEngineeringAgent\":\n",
    "                print(\"ðŸ› ï¸ Calling Feature Engineering Agent...\")\n",
    "                # feature_engineer.run(info[\"data_path\"])\n",
    "\n",
    "            elif agent == \"ModelTrainingAgent\":\n",
    "                print(\"ðŸ¤– Calling Model Training Agent...\")\n",
    "                # model_trainer.run(info[\"data_path\"], info[\"target_column\"])\n",
    "                model_training = ModelTrainingAgent(thread_id)\n",
    "                model_training.run()\n",
    "\n",
    "            else:\n",
    "                print(f\"âš ï¸ Unknown agent: {agent}\")\n",
    "\n",
    "    def get_response(self, thread_id, query):\n",
    "\n",
    "        # Default structure if file does not exist\n",
    "        default_info = {\n",
    "            \"session_id\": thread_id,\n",
    "            \"dataset_path\": None,\n",
    "            \"target_column\": None,\n",
    "            \"task_type\": None,\n",
    "            \"task_intent\": None,\n",
    "            \"agents_to_call\": [],\n",
    "            \"model_type\": \"auto\",\n",
    "            \"metrics\": \"auto\",\n",
    "            \"status\": \"init\",\n",
    "            \"timestamp\": None\n",
    "        }\n",
    "\n",
    "        json_file_path = f\"./ml_task_memory/info_{thread_id}.json\"\n",
    "        if not os.path.exists(json_file_path):\n",
    "            with open(json_file_path, \"w\") as f:\n",
    "                json.dump(default_info, f, indent=2)\n",
    "\n",
    "        with open(json_file_path, \"r\") as f:\n",
    "            info = json.load(f)\n",
    "\n",
    "        \n",
    "        if self.is_info_complete(info):\n",
    "            print(\"All required fields collected. Calling downstream tools...\")\n",
    "            print(json.dumps(info, indent=2))  # Show current info to user\n",
    "\n",
    "            confirm = input(\"âš ï¸ Do you want to proceed with these settings? (yes/no): \").strip().lower()\n",
    "            if confirm == \"yes\":\n",
    "                print(\"ðŸš€ Proceeding with downstream agents...\")\n",
    "                self.call_agents(info, thread_id)\n",
    "            else:\n",
    "                print(\"â¹ï¸ Process halted. You can provide more input to adjust settings.\")\n",
    "\n",
    "\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "        previous_messages = self.file_memory.load_messages(thread_id)\n",
    "        input_messages = previous_messages + [HumanMessage(content=query)]\n",
    "\n",
    "        state = {\"messages\": input_messages}\n",
    "        output = self.app.invoke(state, config)\n",
    "\n",
    "        self.file_memory.save_messages(thread_id, output[\"messages\"])\n",
    "\n",
    "        # json_file_path = f\"./ml_task_memory/info_{thread_id}.json\"\n",
    "\n",
    "        \n",
    "\n",
    "        # # Create file with default structure if it doesn't exist\n",
    "\n",
    "        # if not os.path.exists(json_file_path):\n",
    "        #     with open(json_file_path, \"w\") as f:\n",
    "        #         json.dump(default_info, f, indent=2)\n",
    "\n",
    "        response = ie(query, thread_id)\n",
    "\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11778df3",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2da694ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields collected. Calling downstream tools...\n",
      "{\n",
      "  \"session_id\": \"id_0\",\n",
      "  \"dataset_path\": \"data/iris.csv\",\n",
      "  \"target_column\": \"variety\",\n",
      "  \"task_type\": \"classification\",\n",
      "  \"task_intent\": \"full pipeline\",\n",
      "  \"agents_to_call\": [\n",
      "    \"EDAAgent\",\n",
      "    \"FeatureEngineeringAgent\",\n",
      "    \"ModelTrainingAgent\"\n",
      "  ],\n",
      "  \"model_type\": \"auto\",\n",
      "  \"metrics\": \"auto\",\n",
      "  \"status\": \"init\",\n",
      "  \"timestamp\": null\n",
      "}\n",
      "ðŸš€ Proceeding with downstream agents...\n",
      "EDAAgent\n",
      "ðŸ“Š Calling EDA Agent...\n",
      "Ensured directory './output/id_0' exists.\n",
      "Code successfully saved to './output/id_0/eda.py'\n",
      "\n",
      "FeatureEngineeringAgent\n",
      "ðŸ› ï¸ Calling Feature Engineering Agent...\n",
      "ModelTrainingAgent\n",
      "ðŸ¤– Calling Model Training Agent...\n",
      "attempt: 0 ------>\n",
      "----------------\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmpe7_gzcvr.py\"\u001b[0m, line \u001b[35m186\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[31mlog_json\u001b[0m\u001b[1;31m({\"train_test_split\": split_info})\u001b[0m\n",
      "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmpe7_gzcvr.py\"\u001b[0m, line \u001b[35m47\u001b[0m, in \u001b[35mlog_json\u001b[0m\n",
      "    \u001b[31mjson.dump\u001b[0m\u001b[1;31m(logs, f, indent=2)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/__init__.py\"\u001b[0m, line \u001b[35m179\u001b[0m, in \u001b[35mdump\u001b[0m\n",
      "    for chunk in \u001b[1;31miterable\u001b[0m:\n",
      "                 \u001b[1;31m^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/encoder.py\"\u001b[0m, line \u001b[35m430\u001b[0m, in \u001b[35m_iterencode\u001b[0m\n",
      "    yield from _iterencode_list(o, _current_indent_level)\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/encoder.py\"\u001b[0m, line \u001b[35m326\u001b[0m, in \u001b[35m_iterencode_list\u001b[0m\n",
      "    yield from chunks\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/encoder.py\"\u001b[0m, line \u001b[35m406\u001b[0m, in \u001b[35m_iterencode_dict\u001b[0m\n",
      "    yield from chunks\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/encoder.py\"\u001b[0m, line \u001b[35m406\u001b[0m, in \u001b[35m_iterencode_dict\u001b[0m\n",
      "    yield from chunks\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/encoder.py\"\u001b[0m, line \u001b[35m406\u001b[0m, in \u001b[35m_iterencode_dict\u001b[0m\n",
      "    yield from chunks\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/encoder.py\"\u001b[0m, line \u001b[35m439\u001b[0m, in \u001b[35m_iterencode\u001b[0m\n",
      "    o = _default(o)\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/encoder.py\"\u001b[0m, line \u001b[35m180\u001b[0m, in \u001b[35mdefault\u001b[0m\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "                    f'is not JSON serializable')\n",
      "\u001b[1;35mTypeError\u001b[0m: \u001b[35mObject of type int64 is not JSON serializable\u001b[0m\n",
      "\n",
      "----------------\n",
      "attempt: 1 ------>\n",
      "----------------\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmp7m0i56af.py\"\u001b[0m, line \u001b[35m101\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[31mlog_json\u001b[0m\u001b[1;31m({\"preprocessing_insights\": preprocessing_insights})\u001b[0m\n",
      "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmp7m0i56af.py\"\u001b[0m, line \u001b[35m64\u001b[0m, in \u001b[35mlog_json\u001b[0m\n",
      "    logs = json.load(f)\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/__init__.py\"\u001b[0m, line \u001b[35m293\u001b[0m, in \u001b[35mload\u001b[0m\n",
      "    return loads(fp.read(),\n",
      "        cls=cls, object_hook=object_hook,\n",
      "        parse_float=parse_float, parse_int=parse_int,\n",
      "        parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/__init__.py\"\u001b[0m, line \u001b[35m346\u001b[0m, in \u001b[35mloads\u001b[0m\n",
      "    return \u001b[31m_default_decoder.decode\u001b[0m\u001b[1;31m(s)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/decoder.py\"\u001b[0m, line \u001b[35m345\u001b[0m, in \u001b[35mdecode\u001b[0m\n",
      "    obj, end = \u001b[31mself.raw_decode\u001b[0m\u001b[1;31m(s, idx=_w(s, 0).end())\u001b[0m\n",
      "               \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/decoder.py\"\u001b[0m, line \u001b[35m363\u001b[0m, in \u001b[35mraw_decode\u001b[0m\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "\u001b[1;35mjson.decoder.JSONDecodeError\u001b[0m: \u001b[35mExpecting value: line 247 column 19 (char 3952)\u001b[0m\n",
      "\n",
      "----------------\n",
      "attempt: 2 ------>\n",
      "----------------\n",
      "Execution timed out.\n",
      "----------------\n",
      "attempt: 3 ------>\n",
      "----------------\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=3. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=3. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=3. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=3. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "\n",
      "----------------\n",
      "Ensured directory './output/id_0' exists.\n",
      "Code successfully saved to './output/id_0/model_training.py'\n",
      "Bot: Understood.  \n",
      "Here are the details:\n",
      "\n",
      "- `data_path`: data/iris.csv  \n",
      "- `data_type`: csv  \n",
      "- `task_type`: classification  \n",
      "- `target_column`: variety  \n",
      "- `task_intent`: full_pipeline  \n",
      "- `agents_to_call`: [\"EdaAgent\", \"FeatureEngineeringAgent\", \"ModelTrainingAgent\"]\n",
      "\n",
      "Proceeding with your pipeline setup.\n"
     ]
    }
   ],
   "source": [
    "# Set up\n",
    "orch = Orchestrator()\n",
    "thread_id = \"id_0\"\n",
    "\n",
    "# Example query\n",
    "# user_input = 'hello'\n",
    "user_input = 'data/iris.csv, data is of type csv, classification and target column is variety, full pipeline'\n",
    "# user_input = 'full pipeline'\n",
    "user_input = 'yes'\n",
    "# Call the orchestrator\n",
    "output = orch.get_response(thread_id, user_input)\n",
    "\n",
    "# Print the final AI message\n",
    "print(\"Bot:\", output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f2b053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields collected. Calling downstream tools...\n",
      "{\n",
      "  \"session_id\": \"id_2\",\n",
      "  \"dataset_path\": \"data/banana_quality.csv\",\n",
      "  \"target_column\": \"Quality\",\n",
      "  \"task_type\": \"classification\",\n",
      "  \"task_intent\": \"full pipeline\",\n",
      "  \"agents_to_call\": [\n",
      "    \"EDAAgent\",\n",
      "    \"FeatureEngineeringAgent\",\n",
      "    \"ModelTrainingAgent\"\n",
      "  ],\n",
      "  \"model_type\": \"auto\",\n",
      "  \"metrics\": \"auto\",\n",
      "  \"status\": \"init\",\n",
      "  \"timestamp\": null\n",
      "}\n",
      "ðŸš€ Proceeding with downstream agents...\n",
      "EDAAgent\n",
      "ðŸ“Š Calling EDA Agent...\n",
      "Ensured directory './output/id_2' exists.\n",
      "Code successfully saved to './output/id_2/eda.py'\n",
      "\n",
      "FeatureEngineeringAgent\n",
      "ðŸ› ï¸ Calling Feature Engineering Agent...\n",
      "ModelTrainingAgent\n",
      "ðŸ¤– Calling Model Training Agent...\n",
      "attempt: 0 ------>\n",
      "----------------\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmpce_99vp8.py\"\u001b[0m, line \u001b[35m210\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    results = cross_validate(\n",
      "        model, X_train, y_train,\n",
      "    ...<3 lines>...\n",
      "        n_jobs=-1\n",
      "    )\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\"\u001b[0m, line \u001b[35m218\u001b[0m, in \u001b[35mwrapper\u001b[0m\n",
      "    return func(*args, **kwargs)\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\"\u001b[0m, line \u001b[35m419\u001b[0m, in \u001b[35mcross_validate\u001b[0m\n",
      "    \u001b[31m_warn_or_raise_about_fit_failures\u001b[0m\u001b[1;31m(results, error_score)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\"\u001b[0m, line \u001b[35m505\u001b[0m, in \u001b[35m_warn_or_raise_about_fit_failures\u001b[0m\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35m\n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/base.py\", line 1363, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py\", line 1239, in fit\n",
      "    X, y = validate_data(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        self,\n",
      "        ^^^^^\n",
      "    ...<5 lines>...\n",
      "        accept_large_sparse=solver not in [\"liblinear\", \"sag\", \"saga\"],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "        X,\n",
      "    ...<12 lines>...\n",
      "        input_name=\"X\",\n",
      "    )\n",
      "  File \"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 929, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "ValueError: at least one array or dtype is required\n",
      "\u001b[0m\n",
      "\n",
      "----------------\n",
      "attempt: 1 ------>\n",
      "----------------\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmprf2jpm83.py\"\u001b[0m, line \u001b[35m108\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    assert \u001b[1;31mlen(selected_features) > 0\u001b[0m, \"No features selected for modeling!\"\n",
      "           \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[1;35mAssertionError\u001b[0m: \u001b[35mNo features selected for modeling!\u001b[0m\n",
      "\n",
      "----------------\n",
      "attempt: 2 ------>\n",
      "----------------\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:42:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:42:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:42:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:42:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:42:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:42:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:42:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "\n",
      "----------------\n",
      "Ensured directory './output/id_2' exists.\n",
      "Code successfully saved to './output/id_2/model_training.py'\n",
      "Bot: Understood. I will initiate the full pipeline for your dataset. Thank you.\n"
     ]
    }
   ],
   "source": [
    "# Set up\n",
    "orch = Orchestrator()\n",
    "thread_id = \"id_2\"\n",
    "\n",
    "# Example query\n",
    "user_input = 'hello'\n",
    "user_input = 'data/banana_quality.csv, data is of type csv, tabular classification and target column is Quality, full pipeline'\n",
    "# user_input = 'full pipeline'\n",
    "user_input = 'yes'\n",
    "# Call the orchestrator\n",
    "output = orch.get_response(thread_id, user_input)\n",
    "\n",
    "# Print the final AI message\n",
    "print(\"Bot:\", output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645a211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36f9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
