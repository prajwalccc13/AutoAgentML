{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb8bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "open_ai_key = \"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\"\n",
    "\n",
    "model = init_chat_model(\"gpt-4.1-nano-2025-04-14\", model_provider=\"openai\", openai_api_key=open_ai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b155e26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tools.info_extractor' from '/Users/prajwalchaudhary/Desktop/Uni/COMP8420/AutoAgentML/tools/info_extractor.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import agents.eda_agent\n",
    "import agents.model_training_agent\n",
    "import tools.info_extractor\n",
    "importlib.reload(agents.model_training_agent)\n",
    "importlib.reload(agents.eda_agent)\n",
    "importlib.reload(tools.info_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccac8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Optional\n",
    "\n",
    "from langgraph.graph import StateGraph, START\n",
    "# from langgraph.checkpoint import MemorySaver\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, messages_from_dict, message_to_dict\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "from tools.info_extractor import info_extractor as ie\n",
    "\n",
    "from agents.eda_agent import EDAAgent\n",
    "from agents.model_training_agent import ModelTrainingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4a3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "orch_prompt = \"\"\"\n",
    "You are an intelligent machine learning assistant that guides users through setting up ML tasks. Your job is to have a professional, efficient conversation to collect the **minimum required information** so that specialized agents (like EdaAgent, FeatureEngineeringAgent, and ModelTrainingAgent) can take over.\n",
    "\n",
    "ðŸŽ¯ Your responsibilities:\n",
    "- Determine the **intent** of the user: Do they want to run EDA, do feature engineering, train a model, or run a full pipeline?\n",
    "- Collect only essential input:\n",
    "  - Dataset directory path (e.g., `./data/train.csv`)\n",
    "  - Type of data (e.g., `csv`, `images`, `text`, etc.)\n",
    "  - Type of task (e.g., `regression`, `classification`, `clustering`, `reinforcement learning`)\n",
    "  - Target column, if the task is supervised\n",
    "\n",
    "ðŸ§  What *not* to do:\n",
    "- Do **not** suggest or select specific models or metrics â€” that is the job of downstream agents.\n",
    "- Do **not** ask the user for algorithms, architectures, or training details.\n",
    "- Do **not** continue once enough information is collected.\n",
    "\n",
    "âœ… When you have everything:\n",
    "- Confirm with the user\n",
    "- Return the following fields:\n",
    "  - `data_path`\n",
    "  - `data_type`\n",
    "  - `task_type`\n",
    "  - `target_column` (if applicable)\n",
    "  - `task_intent` (e.g., `eda`, `model_training`, `full_pipeline`)\n",
    "  - `agents_to_call` = list of selected agents based on intent\n",
    "\n",
    "Examples:\n",
    "- If user says: \"I want to run EDA on ./data.csv\" â†’ set task_intent: `eda`, agents_to_call: `[\"EdaAgent\"]`\n",
    "- If user says: \"I want to build a model to predict price from a CSV file\" â†’ set task_type: `regression`, task_intent: `full_pipeline`, collect target column\n",
    "\n",
    "Respond in a professional and concise tone.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    orch_prompt,\n",
    "                ),\n",
    "                MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b0950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLTaskState(BaseModel):\n",
    "    messages: list[BaseMessage]\n",
    "    task_type: Optional[str] = None\n",
    "    target_column: Optional[str] = None\n",
    "    agents_to_call: Optional[list[str]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f7fba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Orchestrator:\n",
    "    def __init__(self):\n",
    "        workflow = StateGraph(state_schema=MessagesState)\n",
    "        workflow.add_edge(START, \"model\")\n",
    "        workflow.add_node(\"model\", self.call_model)\n",
    "\n",
    "        memory = MemorySaver()\n",
    "        self.app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "    def prompt_template_getter(self):\n",
    "        prompt_template = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    orch_prompt,\n",
    "                ),\n",
    "                MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            ]\n",
    "        )\n",
    "        return prompt_template\n",
    "\n",
    "    def call_model(self, state: MessagesState):\n",
    "        prompt = self.prompt_template_getter().invoke(state)\n",
    "        response = model.invoke(prompt)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    def get_response(self, thread_id, query):\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "        input_messages = [HumanMessage(query)]\n",
    "        output = self.app.invoke(\n",
    "            {\"messages\": input_messages},\n",
    "            config,\n",
    "        )\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8978d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you with your machine learning task today? Are you looking to perform data analysis, feature engineering, model training, or a full pipeline?\n"
     ]
    }
   ],
   "source": [
    "orch = Orchestrator()\n",
    "output = orch.get_response('2', 'Hello')\n",
    "output[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fdad4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d2fbad4",
   "metadata": {},
   "source": [
    "## CUstom Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "869146c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FILE MEMORY ===\n",
    "class MLTaskFileMemory:\n",
    "    def __init__(self, base_dir=\"ml_task_memory\"):\n",
    "        self.base_dir = base_dir\n",
    "        os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "    def _msg_path(self, thread_id):\n",
    "        return os.path.join(self.base_dir, f\"messages_{thread_id}.json\")\n",
    "\n",
    "    def _info_path(self, thread_id):\n",
    "        return os.path.join(self.base_dir, f\"info_{thread_id}.json\")\n",
    "\n",
    "    def save_messages(self, thread_id, messages: List[BaseMessage]):\n",
    "        with open(self._msg_path(thread_id), \"w\") as f:\n",
    "            json.dump([message_to_dict(m) for m in messages], f, indent=2)\n",
    "\n",
    "    def load_messages(self, thread_id):\n",
    "        try:\n",
    "            with open(self._msg_path(thread_id), \"r\") as f:\n",
    "                content = f.read().strip()\n",
    "                return messages_from_dict(json.loads(content)) if content else []\n",
    "        except (FileNotFoundError, json.JSONDecodeError):\n",
    "            return []\n",
    "\n",
    "    def save_info(self, thread_id, task_type, target_column, agents_to_call, data_path=None, data_type=None, task_intent=None):\n",
    "        info = {\n",
    "            \"session_id\": thread_id,\n",
    "            \"data_path\": data_path,\n",
    "            \"data_type\": data_type,\n",
    "            \"task_type\": task_type,\n",
    "            \"target_column\": target_column,\n",
    "            \"task_intent\": task_intent,\n",
    "            \"agents_to_call\": agents_to_call,\n",
    "            \"model_type\": \"auto\",\n",
    "            \"metrics\": \"auto\",\n",
    "            \"status\": \"ready\",\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        with open(self._info_path(thread_id), \"w\") as f:\n",
    "            json.dump(info, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86edd7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === ORCHESTRATOR ===\n",
    "class Orchestrator:\n",
    "    def __init__(self):\n",
    "        workflow = StateGraph(state_schema=dict)\n",
    "        workflow.add_edge(START, \"model\")\n",
    "        workflow.add_node(\"model\", self.call_model)\n",
    "\n",
    "        memory = MemorySaver()\n",
    "        self.app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "        self.file_memory = MLTaskFileMemory()\n",
    "\n",
    "    def prompt_template_getter(self):\n",
    "        return ChatPromptTemplate.from_messages([\n",
    "            (\"system\", orch_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"messages\")\n",
    "        ])\n",
    "\n",
    "    def call_model(self, state: dict):\n",
    "        prompt = self.prompt_template_getter().invoke({\"messages\": state[\"messages\"]})\n",
    "        response = model.invoke(prompt)\n",
    "        return {\"messages\": state[\"messages\"] + [response]}\n",
    "\n",
    "    def is_info_complete(self, info: dict):\n",
    "        required_fields = [\"dataset_path\", \"task_intent\", \"agents_to_call\"]\n",
    "        return all(info.get(field) for field in required_fields)\n",
    "\n",
    "    def call_agents(self, info: dict, thread_id):\n",
    "        for agent in info[\"agents_to_call\"]:\n",
    "            print(agent)\n",
    "            if agent == \"EDAAgent\":\n",
    "                print(\"ðŸ“Š Calling EDA Agent...\")\n",
    "                # eda_agent.run(info[\"data_path\"]) or enqueue job\n",
    "                eda_agent = EDAAgent(thread_id)\n",
    "                eda_agent.run()\n",
    "\n",
    "            elif agent == \"FeatureEngineeringAgent\":\n",
    "                print(\"ðŸ› ï¸ Calling Feature Engineering Agent...\")\n",
    "                # feature_engineer.run(info[\"data_path\"])\n",
    "\n",
    "            elif agent == \"ModelTrainingAgent\":\n",
    "                print(\"ðŸ¤– Calling Model Training Agent...\")\n",
    "                # model_trainer.run(info[\"data_path\"], info[\"target_column\"])\n",
    "                model_training = ModelTrainingAgent(thread_id)\n",
    "                model_training.run()\n",
    "\n",
    "            else:\n",
    "                print(f\"âš ï¸ Unknown agent: {agent}\")\n",
    "\n",
    "    def get_response(self, thread_id, query):\n",
    "\n",
    "        # Default structure if file does not exist\n",
    "        default_info = {\n",
    "            \"session_id\": thread_id,\n",
    "            \"dataset_path\": None,\n",
    "            \"target_column\": None,\n",
    "            \"task_type\": None,\n",
    "            \"task_intent\": None,\n",
    "            \"agents_to_call\": [],\n",
    "            \"model_type\": \"auto\",\n",
    "            \"metrics\": \"auto\",\n",
    "            \"status\": \"init\",\n",
    "            \"timestamp\": None\n",
    "        }\n",
    "\n",
    "        json_file_path = f\"./ml_task_memory/info_{thread_id}.json\"\n",
    "        if not os.path.exists(json_file_path):\n",
    "            with open(json_file_path, \"w\") as f:\n",
    "                json.dump(default_info, f, indent=2)\n",
    "\n",
    "        with open(json_file_path, \"r\") as f:\n",
    "            info = json.load(f)\n",
    "\n",
    "        \n",
    "        if self.is_info_complete(info):\n",
    "            print(\"All required fields collected. Calling downstream tools...\")\n",
    "            print(json.dumps(info, indent=2))  # Show current info to user\n",
    "\n",
    "            confirm = input(\"âš ï¸ Do you want to proceed with these settings? (yes/no): \").strip().lower()\n",
    "            if confirm == \"yes\":\n",
    "                print(\"ðŸš€ Proceeding with downstream agents...\")\n",
    "                self.call_agents(info, thread_id)\n",
    "            else:\n",
    "                print(\"â¹ï¸ Process halted. You can provide more input to adjust settings.\")\n",
    "\n",
    "\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "        previous_messages = self.file_memory.load_messages(thread_id)\n",
    "        input_messages = previous_messages + [HumanMessage(content=query)]\n",
    "\n",
    "        state = {\"messages\": input_messages}\n",
    "        output = self.app.invoke(state, config)\n",
    "\n",
    "        self.file_memory.save_messages(thread_id, output[\"messages\"])\n",
    "\n",
    "        # json_file_path = f\"./ml_task_memory/info_{thread_id}.json\"\n",
    "\n",
    "        \n",
    "\n",
    "        # # Create file with default structure if it doesn't exist\n",
    "\n",
    "        # if not os.path.exists(json_file_path):\n",
    "        #     with open(json_file_path, \"w\") as f:\n",
    "        #         json.dump(default_info, f, indent=2)\n",
    "\n",
    "        response = ie(query, thread_id)\n",
    "\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2da694ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields collected. Calling downstream tools...\n",
      "{\n",
      "  \"session_id\": \"id_0\",\n",
      "  \"dataset_path\": \"data/iris.csv\",\n",
      "  \"target_column\": \"variety\",\n",
      "  \"task_type\": \"classification\",\n",
      "  \"task_intent\": \"full pipeline\",\n",
      "  \"agents_to_call\": [\n",
      "    \"EDAAgent\",\n",
      "    \"FeatureEngineeringAgent\",\n",
      "    \"ModelTrainingAgent\"\n",
      "  ],\n",
      "  \"model_type\": \"auto\",\n",
      "  \"metrics\": \"auto\",\n",
      "  \"status\": \"init\",\n",
      "  \"timestamp\": null\n",
      "}\n",
      "ðŸš€ Proceeding with downstream agents...\n",
      "EDAAgent\n",
      "ðŸ“Š Calling EDA Agent...\n",
      "Ensured directory './output/id_0' exists.\n",
      "Code successfully saved to './output/id_0/eda.py'\n",
      "\n",
      "FeatureEngineeringAgent\n",
      "ðŸ› ï¸ Calling Feature Engineering Agent...\n",
      "ModelTrainingAgent\n",
      "ðŸ¤– Calling Model Training Agent...\n",
      "attempt: 0 ------>\n",
      "----------------\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmpe7_gzcvr.py\"\u001b[0m, line \u001b[35m186\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[31mlog_json\u001b[0m\u001b[1;31m({\"train_test_split\": split_info})\u001b[0m\n",
      "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmpe7_gzcvr.py\"\u001b[0m, line \u001b[35m47\u001b[0m, in \u001b[35mlog_json\u001b[0m\n",
      "    \u001b[31mjson.dump\u001b[0m\u001b[1;31m(logs, f, indent=2)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/__init__.py\"\u001b[0m, line \u001b[35m179\u001b[0m, in \u001b[35mdump\u001b[0m\n",
      "    for chunk in \u001b[1;31miterable\u001b[0m:\n",
      "                 \u001b[1;31m^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/encoder.py\"\u001b[0m, line \u001b[35m430\u001b[0m, in \u001b[35m_iterencode\u001b[0m\n",
      "    yield from _iterencode_list(o, _current_indent_level)\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/encoder.py\"\u001b[0m, line \u001b[35m326\u001b[0m, in \u001b[35m_iterencode_list\u001b[0m\n",
      "    yield from chunks\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/encoder.py\"\u001b[0m, line \u001b[35m406\u001b[0m, in \u001b[35m_iterencode_dict\u001b[0m\n",
      "    yield from chunks\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/encoder.py\"\u001b[0m, line \u001b[35m406\u001b[0m, in \u001b[35m_iterencode_dict\u001b[0m\n",
      "    yield from chunks\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/encoder.py\"\u001b[0m, line \u001b[35m406\u001b[0m, in \u001b[35m_iterencode_dict\u001b[0m\n",
      "    yield from chunks\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/encoder.py\"\u001b[0m, line \u001b[35m439\u001b[0m, in \u001b[35m_iterencode\u001b[0m\n",
      "    o = _default(o)\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/encoder.py\"\u001b[0m, line \u001b[35m180\u001b[0m, in \u001b[35mdefault\u001b[0m\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "                    f'is not JSON serializable')\n",
      "\u001b[1;35mTypeError\u001b[0m: \u001b[35mObject of type int64 is not JSON serializable\u001b[0m\n",
      "\n",
      "----------------\n",
      "attempt: 1 ------>\n",
      "----------------\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmp7m0i56af.py\"\u001b[0m, line \u001b[35m101\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[31mlog_json\u001b[0m\u001b[1;31m({\"preprocessing_insights\": preprocessing_insights})\u001b[0m\n",
      "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmp7m0i56af.py\"\u001b[0m, line \u001b[35m64\u001b[0m, in \u001b[35mlog_json\u001b[0m\n",
      "    logs = json.load(f)\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/__init__.py\"\u001b[0m, line \u001b[35m293\u001b[0m, in \u001b[35mload\u001b[0m\n",
      "    return loads(fp.read(),\n",
      "        cls=cls, object_hook=object_hook,\n",
      "        parse_float=parse_float, parse_int=parse_int,\n",
      "        parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/__init__.py\"\u001b[0m, line \u001b[35m346\u001b[0m, in \u001b[35mloads\u001b[0m\n",
      "    return \u001b[31m_default_decoder.decode\u001b[0m\u001b[1;31m(s)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/decoder.py\"\u001b[0m, line \u001b[35m345\u001b[0m, in \u001b[35mdecode\u001b[0m\n",
      "    obj, end = \u001b[31mself.raw_decode\u001b[0m\u001b[1;31m(s, idx=_w(s, 0).end())\u001b[0m\n",
      "               \u001b[31m~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/json/decoder.py\"\u001b[0m, line \u001b[35m363\u001b[0m, in \u001b[35mraw_decode\u001b[0m\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "\u001b[1;35mjson.decoder.JSONDecodeError\u001b[0m: \u001b[35mExpecting value: line 247 column 19 (char 3952)\u001b[0m\n",
      "\n",
      "----------------\n",
      "attempt: 2 ------>\n",
      "----------------\n",
      "Execution timed out.\n",
      "----------------\n",
      "attempt: 3 ------>\n",
      "----------------\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=3. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=3. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1288: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=3. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:22:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 1 is smaller than n_iter=3. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "\n",
      "----------------\n",
      "Ensured directory './output/id_0' exists.\n",
      "Code successfully saved to './output/id_0/model_training.py'\n",
      "Bot: Understood.  \n",
      "Here are the details:\n",
      "\n",
      "- `data_path`: data/iris.csv  \n",
      "- `data_type`: csv  \n",
      "- `task_type`: classification  \n",
      "- `target_column`: variety  \n",
      "- `task_intent`: full_pipeline  \n",
      "- `agents_to_call`: [\"EdaAgent\", \"FeatureEngineeringAgent\", \"ModelTrainingAgent\"]\n",
      "\n",
      "Proceeding with your pipeline setup.\n"
     ]
    }
   ],
   "source": [
    "# Set up\n",
    "orch = Orchestrator()\n",
    "thread_id = \"id_0\"\n",
    "\n",
    "# Example query\n",
    "# user_input = 'hello'\n",
    "user_input = 'data/iris.csv, data is of type csv, classification and target column is variety, full pipeline'\n",
    "# user_input = 'full pipeline'\n",
    "user_input = 'yes'\n",
    "# Call the orchestrator\n",
    "output = orch.get_response(thread_id, user_input)\n",
    "\n",
    "# Print the final AI message\n",
    "print(\"Bot:\", output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f2b053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields collected. Calling downstream tools...\n",
      "{\n",
      "  \"session_id\": \"id_2\",\n",
      "  \"dataset_path\": \"data/banana_quality.csv\",\n",
      "  \"target_column\": \"Quality\",\n",
      "  \"task_type\": \"classification\",\n",
      "  \"task_intent\": \"full pipeline\",\n",
      "  \"agents_to_call\": [\n",
      "    \"EDAAgent\",\n",
      "    \"FeatureEngineeringAgent\",\n",
      "    \"ModelTrainingAgent\"\n",
      "  ],\n",
      "  \"model_type\": \"auto\",\n",
      "  \"metrics\": \"auto\",\n",
      "  \"status\": \"init\",\n",
      "  \"timestamp\": null\n",
      "}\n",
      "ðŸš€ Proceeding with downstream agents...\n",
      "EDAAgent\n",
      "ðŸ“Š Calling EDA Agent...\n",
      "Ensured directory './output/id_2' exists.\n",
      "Code successfully saved to './output/id_2/eda.py'\n",
      "\n",
      "FeatureEngineeringAgent\n",
      "ðŸ› ï¸ Calling Feature Engineering Agent...\n",
      "ModelTrainingAgent\n",
      "ðŸ¤– Calling Model Training Agent...\n",
      "attempt: 0 ------>\n",
      "----------------\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmpce_99vp8.py\"\u001b[0m, line \u001b[35m210\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    results = cross_validate(\n",
      "        model, X_train, y_train,\n",
      "    ...<3 lines>...\n",
      "        n_jobs=-1\n",
      "    )\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/utils/_param_validation.py\"\u001b[0m, line \u001b[35m218\u001b[0m, in \u001b[35mwrapper\u001b[0m\n",
      "    return func(*args, **kwargs)\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\"\u001b[0m, line \u001b[35m419\u001b[0m, in \u001b[35mcross_validate\u001b[0m\n",
      "    \u001b[31m_warn_or_raise_about_fit_failures\u001b[0m\u001b[1;31m(results, error_score)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\"\u001b[0m, line \u001b[35m505\u001b[0m, in \u001b[35m_warn_or_raise_about_fit_failures\u001b[0m\n",
      "    raise ValueError(all_fits_failed_message)\n",
      "\u001b[1;35mValueError\u001b[0m: \u001b[35m\n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/base.py\", line 1363, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py\", line 1239, in fit\n",
      "    X, y = validate_data(\n",
      "           ~~~~~~~~~~~~~^\n",
      "        self,\n",
      "        ^^^^^\n",
      "    ...<5 lines>...\n",
      "        accept_large_sparse=solver not in [\"liblinear\", \"sag\", \"saga\"],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 2971, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 1368, in check_X_y\n",
      "    X = check_array(\n",
      "        X,\n",
      "    ...<12 lines>...\n",
      "        input_name=\"X\",\n",
      "    )\n",
      "  File \"/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 929, in check_array\n",
      "    dtype_orig = np.result_type(*dtypes_orig)\n",
      "ValueError: at least one array or dtype is required\n",
      "\u001b[0m\n",
      "\n",
      "----------------\n",
      "attempt: 1 ------>\n",
      "----------------\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmprf2jpm83.py\"\u001b[0m, line \u001b[35m108\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    assert \u001b[1;31mlen(selected_features) > 0\u001b[0m, \"No features selected for modeling!\"\n",
      "           \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "\u001b[1;35mAssertionError\u001b[0m: \u001b[35mNo features selected for modeling!\u001b[0m\n",
      "\n",
      "----------------\n",
      "attempt: 2 ------>\n",
      "----------------\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:42:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:42:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:42:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:42:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:42:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:42:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [19:42:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "\n",
      "----------------\n",
      "Ensured directory './output/id_2' exists.\n",
      "Code successfully saved to './output/id_2/model_training.py'\n",
      "Bot: Understood. I will initiate the full pipeline for your dataset. Thank you.\n"
     ]
    }
   ],
   "source": [
    "# Set up\n",
    "orch = Orchestrator()\n",
    "thread_id = \"id_2\"\n",
    "\n",
    "# Example query\n",
    "user_input = 'hello'\n",
    "user_input = 'data/banana_quality.csv, data is of type csv, tabular classification and target column is Quality, full pipeline'\n",
    "# user_input = 'full pipeline'\n",
    "user_input = 'yes'\n",
    "# Call the orchestrator\n",
    "output = orch.get_response(thread_id, user_input)\n",
    "\n",
    "# Print the final AI message\n",
    "print(\"Bot:\", output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af64dc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields collected. Calling downstream tools...\n",
      "{\n",
      "  \"session_id\": \"id_4\",\n",
      "  \"dataset_path\": \"data/Crop_Yield_Prediction.csv\",\n",
      "  \"target_column\": \"Yield\",\n",
      "  \"task_type\": \"tabular regression\",\n",
      "  \"task_intent\": \"regression\",\n",
      "  \"agents_to_call\": [\n",
      "    \"EDAAgent\",\n",
      "    \"FeatureEngineeringAgent\",\n",
      "    \"ModelTrainingAgent\"\n",
      "  ],\n",
      "  \"model_type\": \"auto\",\n",
      "  \"metrics\": \"auto\",\n",
      "  \"status\": \"init\",\n",
      "  \"timestamp\": null\n",
      "}\n",
      "ðŸš€ Proceeding with downstream agents...\n",
      "EDAAgent\n",
      "ðŸ“Š Calling EDA Agent...\n",
      "Ensured directory './output/id_4' exists.\n",
      "Code successfully saved to './output/id_4/eda.py'\n",
      "/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmphafu66xc.py:38: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif pd.api.types.is_categorical_dtype(df[col]):\n",
      "\n",
      "FeatureEngineeringAgent\n",
      "ðŸ› ï¸ Calling Feature Engineering Agent...\n",
      "ModelTrainingAgent\n",
      "ðŸ¤– Calling Model Training Agent...\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-O8lyBYJjFIDFh654RddDCssY on tokens per min (TPM): Limit 30000, Requested 69557. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m user_input = \u001b[33m'\u001b[39m\u001b[33myes\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Call the orchestrator\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m output = \u001b[43morch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Print the final AI message\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBot:\u001b[39m\u001b[33m\"\u001b[39m, output[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m].content)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 82\u001b[39m, in \u001b[36mOrchestrator.get_response\u001b[39m\u001b[34m(self, thread_id, query)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m confirm == \u001b[33m\"\u001b[39m\u001b[33myes\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸš€ Proceeding with downstream agents...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_agents\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâ¹ï¸ Process halted. You can provide more input to adjust settings.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mOrchestrator.call_agents\u001b[39m\u001b[34m(self, info, thread_id)\u001b[39m\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# model_trainer.run(info[\"data_path\"], info[\"target_column\"])\u001b[39;00m\n\u001b[32m     44\u001b[39m     model_training = ModelTrainingAgent(thread_id)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[43mmodel_training\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâš ï¸ Unknown agent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Uni/COMP8420/AutoAgentML/agents/model_training_agent.py:100\u001b[39m, in \u001b[36mModelTrainingAgent.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     98\u001b[39m     \u001b[38;5;66;03m# Plan the work\u001b[39;00m\n\u001b[32m     99\u001b[39m     planning_prompt = \u001b[38;5;28mself\u001b[39m.get_planning_prompt()\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     plan_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplanning_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     \u001b[38;5;66;03m# code generation\u001b[39;00m\n\u001b[32m    103\u001b[39m     list_text = plan_response.output_text\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Uni/COMP8420/AutoAgentML/agents/model_training_agent.py:30\u001b[39m, in \u001b[36mModelTrainingAgent.get_response\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt):\n\u001b[32m     29\u001b[39m     client = OpenAI()\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/openai/resources/responses/responses.py:690\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, input, model, background, include, instructions, max_output_tokens, metadata, parallel_tool_calls, previous_response_id, reasoning, service_tier, store, stream, temperature, text, tool_choice, tools, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    659\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    661\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    688\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    689\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/agentml/lib/python3.13/site-packages/openai/_base_client.py:1037\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1034\u001b[39m             err.response.read()\n\u001b[32m   1036\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'Request too large for gpt-4.1 in organization org-O8lyBYJjFIDFh654RddDCssY on tokens per min (TPM): Limit 30000, Requested 69557. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "# Set up\n",
    "orch = Orchestrator()\n",
    "thread_id = \"id_4\"\n",
    "\n",
    "# Example query\n",
    "user_input = 'hello'\n",
    "user_input = 'data/Crop_Yield_Prediction.csv, data is of type csv, task intent is tabular regression and target column is Yield'\n",
    "# user_input = 'task intent ull pipeline'\n",
    "user_input = 'yes'\n",
    "# Call the orchestrator\n",
    "output = orch.get_response(thread_id, user_input)\n",
    "\n",
    "# Print the final AI message\n",
    "print(\"Bot:\", output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "e3c46f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required fields collected. Calling downstream tools...\n",
      "{\n",
      "  \"session_id\": \"11\",\n",
      "  \"dataset_path\": \"data/banana_quality.csv\",\n",
      "  \"target_column\": \"Quality\",\n",
      "  \"task_intent\": \"Build a machine learning model to classify banana quality as Good or Bad based on various features, aiming for at least 0.98 accuracy.\",\n",
      "  \"agents_to_call\": [\n",
      "    \"EDAAgent\",\n",
      "    \"FeatureEngineeringAgent\",\n",
      "    \"ModelTrainingAgent\"\n",
      "  ],\n",
      "  \"model_type\": \"auto\",\n",
      "  \"metrics\": \"auto\",\n",
      "  \"status\": \"init\",\n",
      "  \"timestamp\": null\n",
      "}\n",
      "ðŸš€ Proceeding with downstream agents...\n",
      "EDAAgent\n",
      "ðŸ“Š Calling EDA Agent...\n",
      "Ensured directory './output/11' exists.\n",
      "Code successfully saved to './output/11/eda.py'\n",
      "/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmpc_gxdyji.py:28: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(col_data) or col_data.nunique(dropna=False) < max(20, len(col_data) // 10):\n",
      "/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmpc_gxdyji.py:28: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  elif is_categorical_dtype(col_data) or col_data.nunique(dropna=False) < max(20, len(col_data) // 10):\n",
      "\n",
      "FeatureEngineeringAgent\n",
      "ðŸ› ï¸ Calling Feature Engineering Agent...\n",
      "ModelTrainingAgent\n",
      "ðŸ¤– Calling Model Training Agent...\n",
      "Ensured directory './output/11' exists.\n",
      "Code successfully saved to './output/11/model_training.py'\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"/var/folders/s1/s3f_rpyj6zv3xss6397vnq0m0000gn/T/tmpty0vuml6.py\"\u001b[0m, line \u001b[35m178\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    corrs_of_interest = [k for k, v in corrs.items() if \u001b[31mabs\u001b[0m\u001b[1;31m(v)\u001b[0m > 0.8]\n",
      "                                                        \u001b[31m~~~\u001b[0m\u001b[1;31m^^^\u001b[0m\n",
      "\u001b[1;35mTypeError\u001b[0m: \u001b[35mbad operand type for abs(): 'dict'\u001b[0m\n",
      "\n",
      "Bot: Based on your confirmation, I will proceed with a full pipeline for classification using the dataset at `data/banana_quality.csv` with the target column `Quality`. \n",
      "\n",
      "Agents to call:\n",
      "- `EdaAgent`\n",
      "- `FeatureEngineeringAgent`\n",
      "- `ModelTrainingAgent`\n",
      "\n",
      "Is that correct?\n"
     ]
    }
   ],
   "source": [
    "# Set up\n",
    "orch = Orchestrator()\n",
    "thread_id = \"11\"\n",
    "\n",
    "# Example query\n",
    "user_input = 'hello'\n",
    "user_input = '''Build a machine learning model to classify banana quality as\n",
    "Good or Bad based on their numerical information about bananas of different quality (size, weight,\n",
    "sweetness, softness, harvest time, ripeness, and acidity). We have uploaded the entire dataset for you\n",
    "here in the data/banana_quality.csv file. The model must achieve at least 0.98 accuracy. target column is Quality'''\n",
    "# user_input = 'full pipeline'\n",
    "# user_input = 'target column is Quality'\n",
    "user_input = 'yes'\n",
    "# Call the orchestrator\n",
    "output = orch.get_response(thread_id, user_input)\n",
    "\n",
    "# Print the final AI message\n",
    "print(\"Bot:\", output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645a211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "354312bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "There\n",
      "Bot: Thank you. Please provide the dataset path and data type (e.g., `csv`, `images`, `text`) so I can complete the setup.\n"
     ]
    }
   ],
   "source": [
    "# Set up\n",
    "orch = Orchestrator()\n",
    "thread_id = \"1x\"\n",
    "\n",
    "# Example query\n",
    "user_input = \"target_column is 'variety'\"\n",
    "\n",
    "# Call the orchestrator\n",
    "output = orch.get_response(thread_id, user_input)\n",
    "\n",
    "# Print the final AI message\n",
    "print(\"Bot:\", output[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b8a0a0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tools.info_extractor' from '/Users/prajwalchaudhary/Desktop/Uni/COMP8420/AutoAgentML/tools/info_extractor.py'>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import tools.info_extractor\n",
    "importlib.reload(tools.info_extractor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "6f78665d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'agents.eda_agent' from '/Users/prajwalchaudhary/Desktop/Uni/COMP8420/AutoAgentML/agents/eda_agent.py'>"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import agents.eda_agent\n",
    "import agents.model_training_agent\n",
    "importlib.reload(agents.model_training_agent)\n",
    "importlib.reload(agents.eda_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36f9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
