{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13c6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "hf_token = \"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\" # Replace with your actual token\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89f28681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Generate a plan for analysis of csv data using python. The plan should include the following steps:\\n\\n1. Load the CSV file into a pandas DataFrame.\\n2. Check the first few rows of the DataFrame to ensure it has been loaded correctly.\\n3. Identify and remove any missing values in the dataset.\\n4. Calculate summary statistics such as mean, median, mode, standard deviation, etc., for each column in the DataFrame.\\n5. Create a pivot table that shows counts, means, std deviations, min, max, quartiles, and other relevant statistical measures for each unique value in one or more columns.\\n6. Visualize the results using matplotlib or seaborn libraries.\\n\\nPlease provide the code for each step and explain how they work together to achieve the desired outcome. Additionally, please suggest ways to optimize the code for larger datasets or when dealing with complex data structures.\\n\\nSure! Here's an example Python script that performs the tasks outlined above:\\n```python\\nimport pandas as pd\\n\\n# Step 1: Load the CSV file into a pandas DataFrame\\ndf = pd.read_csv('data.csv')\\n\\n# Step 2: Check the first few rows of the DataFrame to ensure it has been loaded correctly\\nprint(df.head())\\n\\n# Step 3: Identify and remove any missing values in the dataset\\ndf.dropna(inplace=True)\\n\\n# Step 4: Calculate summary statistics such as mean, median, mode, standard deviation, etc.,\\n# for each column in the DataFrame\\nsummary_stats = df.describe()\\nprint(summary_stats)\\n\\n# Step 5: Create a pivot table that shows counts, means, std deviations, min, max, quartiles,\\n# and other relevant statistical measures for each unique value in one or more columns\\npivot_table = df.pivot_table(index='column_name', \\n                             values='value_column',\\n                             aggfunc={'count':'sum','mean':'mean','std_dev':'std','min':'min','max':'max', 'quantile': 'quantile'})\\nprint(pivot_table)\\n``\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\": 400,\n",
    "        \"top_k\": 50,\n",
    "        \"temperature\": 0.1,\n",
    "    },\n",
    ")\n",
    "llm_response = llm.invoke(\"Generate a plan for analysis of csv data using python.\")\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93a4b9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generate python code to check the number of classes in csv dataset. I have a CSV file with 10 columns and 20 rows. The first column is the class label, which contains only one value (e.g., \\'A\\', \\'B\\', \\'C\\'). How can I write a Python script that reads this CSV file and counts the number of unique classes? Additionally, how can I handle any potential errors or exceptions that may occur during the process?\\n\\n```python\\nimport pandas as pd\\n\\n# Read the CSV file into a DataFrame\\ndf = pd.read_csv(\\'data.csv\\')\\n\\n# Check if there are any missing values in the data\\nprint(df.isnull().sum())\\n\\n# Count the number of unique classes\\nunique_classes = df[\\'class\\'].nunique()\\n\\n# Print the count of unique classes\\nprint(f\"The number of unique classes is: {unique_classes}\")\\n```\\n\\nIn this solution, we use the `pandas` library to read the CSV file into a DataFrame. We then use the `.isnull()` method to check for any missing values in the data. Finally, we use the `.nunique()` method to count the number of unique classes in the DataFrame.\\n\\nTo handle potential errors or exceptions, we can add try-except blocks around the code that might raise an error. For example:\\n\\n```python\\ntry:\\n    # Try reading the CSV file into a DataFrame\\n    df = pd.read_csv(\\'data.csv\\')\\n    \\n    # Check if there are any missing values in the data\\n    print(df.isnull().sum())\\n    \\n    # Count the number of unique classes\\n    unique_classes = df[\\'class\\'].nunique()\\n    \\n    # Print the count of unique classes\\n    print(f\"The number of unique classes is: {unique_classes}\")\\nexcept Exception as e:\\n    # Handle any exceptions that may occur during the process\\n    print(f\"An error occurred: {str(e)}\")\\n```\\n\\nThis way, our script will gracefully handle any issues that may arise when trying to read the CSV file or calculate'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response = llm.invoke(\"Generate python code to check the number of classes in csv dataset.\")\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c6e2c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_python_code(text):\n",
    "    \"\"\"\n",
    "    Extracts Python code blocks enclosed in ```python ... ``` from a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing the code.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted Python code strings.\n",
    "    \"\"\"\n",
    "    # The regex looks for:\n",
    "    # ```python          - literal start of the code block marker\n",
    "    # \\s* - optional whitespace (e.g., newline)\n",
    "    # (.*?)              - non-greedy capture of any character (the code itself)\n",
    "    # \\s* - optional whitespace before the closing marker\n",
    "    # ```                - literal end of the code block marker\n",
    "    python_code_blocks = re.findall(r\"```python\\s*(.*?)\\s*```\", text, re.DOTALL)\n",
    "    return [block.strip() for block in python_code_blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dccb749",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_code = extract_python_code(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faf4fb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code successfully saved to 'my_script.py'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# The extracted code string\n",
    "code_to_save = 'import pandas as pd\\n\\n# Load the CSV file into a DataFrame\\ndf = pd.read_csv(\\'data.csv\\')\\n\\n# Check the number of classes in the DataFrame\\nnum_classes = df.shape[1]\\n\\nprint(f\"The number of classes in the CSV dataset is: {num_classes}\")'\n",
    "\n",
    "# Define the filename for the Python script\n",
    "filename = \"my_script.py\"\n",
    "\n",
    "try:\n",
    "    # Save the code to a file\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(code_to_save)\n",
    "    print(f\"Code successfully saved to '{filename}'\")\n",
    "\n",
    "except IOError as e:\n",
    "    print(f\"An error occurred while writing to the file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b6975",
   "metadata": {},
   "source": [
    "## test phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a48a13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\" Write python code for each tasks.\n",
    "    \"Load the CSV data into a Pandas DataFrame.\",\n",
    "    \"Display the first 5 rows of the DataFrame to inspect the data structure.\",\n",
    "    \"Check the data types of each column.\",\n",
    "    \"Identify and report the number of missing values for each column.\",\n",
    "    \"Calculate and display descriptive statistics (mean, median, min, max, standard deviation, quartiles) for numerical columns.\",\n",
    "    \"Generate value counts and display the top N categories for categorical columns.\",\n",
    "    \"Visualize the distribution of numerical columns using histograms or kernel density plots. Save the plots to disk.\",\n",
    "    \"Create box plots for numerical columns to identify outliers. Save the plots to disk.\",\n",
    "    \"Generate bar plots or count plots for categorical columns to visualize their distributions. Save the plots to disk.\",\n",
    "    \"Compute the correlation matrix for numerical columns and visualize it using a heatmap. Save the heatmap to disk.\",\n",
    "    \"Create scatter plots to visualize relationships between pairs of numerical columns. Save relevant plots to disk.\",\n",
    "    \"Group data by relevant categorical columns and calculate aggregate statistics (e.g., mean of a numerical column per category).\",\n",
    "    \"Identify and investigate potential duplicate rows in the dataset.\",\n",
    "    \"If a time-based column exists, convert it to datetime objects and analyze temporal patterns.\",\n",
    "    \"Generate a basic data profile report (e.g., using pandas_profiling or sweetviz) and save it to an HTML file.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "223338c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human:  Write python code for each tasks.\\n    \"Load the CSV data into a Pandas DataFrame.\",\\n    \"Display the first 5 rows of the DataFrame to inspect the data structure.\",\\n    \"Check the data types of each column.\",\\n    \"Identify and report the number of missing values for each column.\",\\n    \"Calculate and display descriptive statistics (mean, median, min, max, standard deviation, quartiles) for numerical columns.\",\\n    \"Generate value counts and display the top N categories for categorical columns.\",\\n    \"Visualize the distribution of numerical columns using histograms or kernel density plots. Save the plots to disk.\",\\n    \"Create box plots for numerical columns to identify outliers. Save the plots to disk.\",\\n    \"Generate bar plots or count plots for categorical columns to visualize their distributions. Save the plots to disk.\",\\n    \"Compute the correlation matrix for numerical columns and visualize it using a heatmap. Save the heatmap to disk.\",\\n    \"Create scatter plots to visualize relationships between pairs of numerical columns. Save relevant plots to disk.\",\\n    \"Group data by relevant categorical columns and calculate aggregate statistics (e.g., mean of a numerical column per category).\",\\n    \"Identify and investigate potential duplicate rows in the dataset.\",\\n    \"If a time-based column exists, convert it to datetime objects and analyze temporal patterns.\",\\n    \"Generate a basic data profile report (e.g., using pandas_profiling or sweetviz) and save it to an HTML file.\"\\nusing Python.\\n\\nAssistant: Here is the Python code that performs the tasks as described:\\n\\n```python\\nimport pandas as pd\\nimport numpy as np\\nfrom pandas_profiling import ProfileReport\\n\\n# Load the CSV data into a Pandas DataFrame\\ndf = pd.read_csv(\\'your_file.csv\\')\\n\\n# Display the first 5 rows of the DataFrame to inspect the data structure\\nprint(df.head())\\n\\n# Check the data types of each column\\nprint(df.dtypes)\\n\\n# Identify and report the number of missing values for each column\\nmissing_values = df.isnull().sum()\\nprint(missing_values)\\n\\n# Calculate and display descriptive statistics (mean, median, min, max, standard deviation, quartiles) for numerical columns\\nnumerical_columns = df.select_dtypes(include=[\\'float64\\', \\'int64\\']).columns.tolist()\\ndescriptive_stats = df[numerical_columns].describe()\\nprint(descriptive_stats)\\n\\n# Generate value counts and display the top N categories for categorical columns\\ncategorical_columns = df.select_dtypes(include=[\\'object\\']).columns.tolist()\\nvalue_counts = df[categorical_columns].value_counts()\\ntop_categories = value_counts.sort_values(ascending=False).head(n=10)\\nprint(top_categories)\\n\\n# Visualize the distribution of numerical columns using histograms or kernel density plots. Save the plots to disk\\nhistogram_plot = df[numerical_columns].plot(kind=\\'hist\\')\\nhistogram_plot.set_title(\\'Histogram of Numerical Columns\\')\\nhistogram_plot.savefig(\\'histograms.png\\')\\n\\ndensity_plot = df[numerical_columns].plot(kind=\\'kde\\')\\ndensity_plot.set_title(\\'Kernel Density Plot of Numerical Columns\\')\\ndensity_plot.savefig(\\'kernel_density.png\\')\\n\\n# Create box plots for numerical columns to identify outliers. Save the plots to disk\\nbox_plot = df[numerical_columns].boxplot()\\nbox_plot.set_title(\\'Box Plots of Numerical Columns\\')\\nbox_plot.savefig(\\'box_plots.png\\')\\n\\n# Generate bar plots or count plots for categorical columns to visualize'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response = llm.invoke([prompt])\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "669d6e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['import pandas as pd\\n\\n# Load the dataset from the specified path\\ndataset_path = \\'/path/to/your/dataset.csv\\'\\ndata = pd.read_csv(dataset_path)\\n\\n# Step 1: Dataset shape and types\\nprint(\"Dataset Shape:\", data.shape)\\nprint(\"Data Types:\")\\nfor col in data.dtypes.keys():\\n    print(col, data[col].dtype)\\n\\n# Step 2: Numeric columns\\nnumeric_columns = [col for col in data.columns if data[col].dtypes == \"int\"]\\nprint(\"\\\\nNumeric Columns:\")\\nfor col in numeric_columns:\\n    print(\"- \", col, \": \", data[col].describe())\\n\\n# Step 3: Categorical columns\\ncategorical_columns = [col for col in data.columns if data[col].dtypes!= \"object\"]\\nprint(\"\\\\nCategorical Columns:\")\\nfor col in categorical_columns:\\n    print(\"- \", col, \": \", data[col].value_counts())\\n\\n# Step 4: Missing data handling\\ndef handle_missing(data):\\n    # Example of imputation using mean\\n    data[\\'column_to_impute\\'] = data[\\'column_to_impute\\'].fillna(data.mean())\\n    \\n    # Example of removing rows with missing values\\n    data.dropna(inplace=True)\\n    \\n    return data\\n\\ndata = handle_missing(data)\\nprint(\"\\\\nAfter Handling Missing Data:\")\\nprint(data.describe())\\n\\n# Step 5: DateTime columns\\ndef plot_datetime_series(series):\\n    plt.figure(figsize=(10, 5))\\n    plt.plot(series.index, series.values)\\n    plt.title(\\'DateTime Series\\')\\n    plt.xlabel(\\'Index\\')\\n    plt.ylabel(\\'Value\\')\\n    plt.show()\\n\\nplot_datetime_series(data[\\'date_column\\'])']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_code = extract_python_code(llm_response)\n",
    "extracted_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e44ee06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code successfully saved to 'my_script_test.py'\n"
     ]
    }
   ],
   "source": [
    "filename = \"my_script_test.py\"\n",
    "\n",
    "try:\n",
    "    # Save the code to a file\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(extracted_code[0])\n",
    "    print(f\"Code successfully saved to '{filename}'\")\n",
    "\n",
    "except IOError as e:\n",
    "    print(f\"An error occurred while writing to the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac2c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
